{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3605642-0515-4a43-866b-6b326db24ad7",
   "metadata": {},
   "source": [
    "Starting Jupyter\n",
    "```\n",
    "python3 -m venv env\n",
    "source env/bin/activate\n",
    "jupyter lab\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2c1ada",
   "metadata": {
    "id": "aa2c1ada"
   },
   "source": [
    "# Dreambooth\n",
    "Some key things to change:\n",
    "- `\"project_name\"`: Change project name to whatever you want. Avoid spaces for everything.\n",
    "- `\"max_training_steps\"`: 2000-4000 is a good range. Choose around 2000 if you have 100 images, and around 4000 if you have 200 images.\n",
    "- `\"class_word\"`: Keep as anthro. Or feral. Or... whatever kind of thing you're doing. But it should be extremely simple, and something the model already recognizes easily. Only matters if using regularization images.\n",
    "- `\"token\"`: Pick a longer, made-up word the model has never seen before. Can really be anything, but make it something like \"blaiddwolfyfromeldenring\". \"Charname+universe\" is easier to remember, imo. This is what you will type in to activate it, so... don't make it insane.\n",
    "- `\"base_model\"`: Change to whichever model you want to train on top of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74825514-34e0-4bdb-ba7b-42003fe58516",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "\n",
    "# This is just the name for the training run, not the token.\n",
    "project_name = \"Sticker Style\"\n",
    "\n",
    "# MAX STEPS\n",
    "max_training_steps = 6000\n",
    "\n",
    "# Match class_word to the category of the regularization images you chose above.\n",
    "class_word = \"anthro\" # Anthro or feral are the best choices.\n",
    "\n",
    "# This is the unique token you are teaching the stable diffusion model.\n",
    "token = \"Sticker Style\" #Can be anything, but pick something rare and easy to remember/type.\n",
    "\n",
    "dreambooth_folder = \"dreambooth\"\n",
    "base_model = \"https://sexy.canine.wf/file/yiffy-ckpt/yiffy-e18.ckpt\"\n",
    "\n",
    "# Owncloud Access\n",
    "from config import *\n",
    "#!pip3 install -r requirements.txt\n",
    "\n",
    "# Used Libs\n",
    "import os\n",
    "import sys\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b971cc0",
   "metadata": {
    "id": "7b971cc0"
   },
   "source": [
    "## Build Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2AsGA1xpNQnb",
   "metadata": {
    "id": "2AsGA1xpNQnb"
   },
   "outputs": [],
   "source": [
    "# Download Repository and cd into it\n",
    "\n",
    "#from git import Repo\n",
    "#repository = \"https://github.com/JoePenna/Dreambooth-Stable-Diffusion\"\n",
    "#path = \"Dreambooth-Stable-Diffusion_\"\n",
    "#Repo.clone_from(repository, path)\n",
    "if not os.path.exists(dreambooth_folder):\n",
    "    !git clone https://github.com/JoePenna/Dreambooth-Stable-Diffusion {dreambooth_folder}\n",
    "    %cd {dreambooth_folder}\n",
    "    !git checkout 605faeaa2f0656bf31ab79749fb5d96b3ca2e69f\n",
    "    !mkdir -p ./training_images\n",
    "else:\n",
    "    print(\"Dreambooth already exists\")\n",
    "    %cd {dreambooth_folder}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1bc458-091b-42f4-a125-c3f0df20f29d",
   "metadata": {
    "id": "9e1bc458-091b-42f4-a125-c3f0df20f29d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install necessities\n",
    "!pip3 install omegaconf\n",
    "!pip3 install einops\n",
    "!pip3 install pytorch-lightning==1.6.5\n",
    "!pip3 install test-tube\n",
    "!pip3 install transformers\n",
    "!pip3 install kornia\n",
    "!pip3 install -e git+https://github.com/CompVis/taming-transformers.git@master#egg=taming-transformers\n",
    "!pip3 install -e git+https://github.com/openai/CLIP.git@main#egg=clip\n",
    "!pip3 install setuptools==59.5.0\n",
    "!pip3 install pillow==9.0.1\n",
    "!pip3 install torchmetrics==0.6.0\n",
    "!pip3 install -e .\n",
    "!pip3 install protobuf==3.20.1\n",
    "#!pip3 install gdown\n",
    "!pip3 install -qq diffusers[\"training\"]==0.3.0 transformers ftfy\n",
    "!pip3 install -qq \"ipywidgets>=7,<8\"\n",
    "!pip3 install huggingface_hub\n",
    "!pip3 install ipywidgets==7.7.1\n",
    "!pip3 install captionizer==1.0.1\n",
    "!pip3 install pyocclient\n",
    "#!pip3 install torch==1.12.1+cu116 torchvision==0.13.1+cu116 --extra-index-url https://download.pytorch.org/whl/cu116"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3455457b-3dbc-4727-8667-6f0fa91e3543",
   "metadata": {},
   "source": [
    "## Download the model to train on top of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca852ef-c16c-47cf-9d37-c212dd68a5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Base Model\n",
    "link = base_model\n",
    "file_name = \"model.ckpt\"\n",
    "if not os.path.exists(file_name):\n",
    "    with open(file_name, \"wb\") as f:\n",
    "        print(\"Downloading %s\" % link)\n",
    "        response = requests.get(link, stream=True)\n",
    "        total_length = response.headers.get('content-length')\n",
    "\n",
    "        if total_length is None: # no content length header\n",
    "            f.write(response.content)\n",
    "        else:\n",
    "            dl = 0\n",
    "            total_length = int(total_length)\n",
    "            for data in response.iter_content(chunk_size=40960):\n",
    "                dl += len(data)\n",
    "                f.write(data)\n",
    "                done = int(50 * dl / total_length)\n",
    "                sys.stdout.write(\"\\r[%s%s]\" % ('=' * done, ' ' * (50-done)) )    \n",
    "                sys.stdout.flush()\n",
    "else:\n",
    "    print(\"Model already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69de2f51-22d1-4be4-8eef-1f63e10dacc6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Training data\n",
    "#### Upload your training images\n",
    "\n",
    "Upload 100-200 images of your character to\n",
    "\n",
    "```\n",
    "{dreambooth_folder}/training_images\n",
    "```\n",
    "\n",
    "Be sure to upload an *even* amount of images, otherwise the training inexplicably stops at 1500 steps.\n",
    "\n",
    "#### The images should be:\n",
    "\n",
    "- Solos only!\n",
    "- Square.\n",
    "- 512x512.\n",
    "- Cropped to contain the most recognizable part of your character.\n",
    "- Don't worry about legs/arms being cropped off, the most important part is the head. The model will make up the rest.\n",
    "- A variety of angles and shots. The model can become overfitted if you only do frontal shots, for instance.\n",
    "- If your character has very distinctive features or markings you want to preserve, make sure they show up in the data often.\n",
    "- Variations of the same image (alt versions/edits) are fine, but don't do too many of the same.\n",
    "- DON'T do black and white or uncolored sketches.\n",
    "- Get as close as possible to the output you'd like to see.\n",
    "\n",
    "A good idea is to use imagemagick for automated cropping. No, it's not the fancy kind that uses algorithms to focus on faces, but it totally works.\n",
    "\n",
    "You're mostly on your own for cropping, but here's some...\n",
    "#### Hints for cropping commands:\n",
    "Windows:\n",
    "\n",
    "`magick *.* -gravity North -crop 1:1 -resize 512x512 -format png ..\\raw1\\image-%d.png`\n",
    "\n",
    "Linux:\n",
    "\n",
    "`find -maxdepth 1 -type f -execdir magick '{}' -gravity North -crop 1:1 -resize 512x512 ../ready1/'{}.png' \\;`\n",
    "\n",
    "https://imagemagick.org/script/download.php\n",
    "\n",
    "\n",
    "#### Use BIRME, it's by far the best option for bulk crop + resize:\n",
    "https://www.birme.net/?target_width=512&target_height=512&rename=ORIGINAL-NAME_&border_width=-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4e50df",
   "metadata": {
    "id": "ad4e50df",
    "tags": []
   },
   "source": [
    "# Training\n",
    "\n",
    "## This is where the magic happens.\n",
    "Do not worry. It will stop at exactly the number of steps you set, even if the progress bar there looks otherwise. The estimate is usually wildly wrong. There is a separate internal counter that is not shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa5dd66-2ca0-4819-907e-802e25583ae6",
   "metadata": {
    "id": "6fa5dd66-2ca0-4819-907e-802e25583ae6",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "#%cd ./Dreambooth-Stable-Diffusion\n",
    "\n",
    "dataset=\"dataset1\"\n",
    "img_data_root = \"./training_images/\"\n",
    "reg_data_root = \"./regularization_images/\" + dataset\n",
    "\n",
    "#!rm -rf training_images/.ipynb_checkpoints\n",
    "\n",
    "import os\n",
    "training_images_folder = \"./training_images/.ipynb_checkpoints\"\n",
    "if os.path.exists(training_images_folder):\n",
    "    os.remove(training_images_folder)\n",
    "\n",
    "if \"uses_reg\" in locals():\n",
    "    !python3 \"main.py\" \\\n",
    "    --base configs/stable-diffusion/v1-finetune_unfrozen.yaml \\\n",
    "    -t \\\n",
    "    --actual_resume \"model.ckpt\" \\\n",
    "    --reg_data_root \"{reg_data_root}\" \\\n",
    "    -n \"{project_name}\" \\\n",
    "    --gpus 0, \\\n",
    "    --data_root \"{img_data_root}\" \\\n",
    "    --max_training_steps {max_training_steps} \\\n",
    "    --class_word \"{class_word}\" \\\n",
    "    --token \"{token}\" \\\n",
    "    --no-test\n",
    "else:\n",
    "    !python3 \"main.py\" \\\n",
    "    --base configs/stable-diffusion/v1-finetune_unfrozen.yaml \\\n",
    "    -t \\\n",
    "    --actual_resume \"model.ckpt\" \\\n",
    "    -n \"{project_name}\" \\\n",
    "    --gpus 0, \\\n",
    "    --data_root \"{img_data_root}\" \\\n",
    "    --max_training_steps {max_training_steps} \\\n",
    "    --token \"{token}\" \\\n",
    "    --no-test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc49d0bd",
   "metadata": {},
   "source": [
    "## Copy and name the checkpoint file\n",
    "\n",
    "Also prints the sha256sum, very helpful for verification/sharing your dreambooth model publicly. Take note of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65e779f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Copy the checkpoint into the `trained_models` folder\n",
    "\n",
    "directory_paths = !ls -d logs/*\n",
    "last_checkpoint_file = directory_paths[-1] + \"/checkpoints/last.ckpt\"\n",
    "training_images = !find training_images/*\n",
    "date_string = !date +\"%Y-%m-%dT%H-%M-%S\"\n",
    "file_name = date_string[-1] + \"_\" + project_name + \"_\" + str(len(training_images)) + \"_training_images_\" +  str(max_training_steps) + \"_max_training_steps_\" + token + \"_token_\" + class_word + \"_class_word.ckpt\"\n",
    "\n",
    "file_name = file_name.replace(\" \", \"_\")\n",
    "\n",
    "!mkdir -p trained_models\n",
    "!mv \"{last_checkpoint_file}\" \"trained_models/{file_name}\"\n",
    "!sha256sum \"trained_models/{file_name}\"\n",
    "\n",
    "print(\"Download your trained model file from trained_models/\" + file_name + \" and use in your favorite Stable Diffusion repo!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10bf6fe-468f-4f40-8bf4-5331dbaf778f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import owncloud\n",
    "import os\n",
    "\n",
    "trained_models_dir = \"/workspace/Dreambooth-Stable-Diffusion/trained_models/n\"\n",
    "oc = owncloud.Client('http://nx.lla.im')\n",
    "oc.login(oc_user, oc_pw)\n",
    "\n",
    "for file_path, directories, files in os.walk(trained_models_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.ckpt'):\n",
    "            full_path = os.path.join(file_path, file)\n",
    "            print(f\"Uploading: {full_path}\")\n",
    "            oc.drop_file(full_path)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99dfbb1-5a71-4369-8ded-cb6580b222aa",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Upload checkpoint directly to Pixeldrain\n",
    "Saves you time and money if you have a slow download speed. Slightly risky, but for some, very worth it. If your rented pod has a fast internet connection, it will upload to pixeldrain very quickly.\n",
    "\n",
    "### It won't show any output while it is uploading. But if it worked, it will print out a link at at the bottom that you can use to download/share your model.\n",
    "\n",
    "Take extra care, this method can go wrong in any number of ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20f277c-fecf-4abe-baa7-20010d5d9746",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/ManuelReschke/go-pd/releases/download/v1.2.1/go-pd_1.2.1_linux_amd64.tar.gz -O ./go-pd.tar.gz\n",
    "!tar -xf ./go-pd.tar.gz go-pd\n",
    "!./go-pd upload \"/workspace/Dreambooth-Stable-Diffusion/trained_models/{file_name}\""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
